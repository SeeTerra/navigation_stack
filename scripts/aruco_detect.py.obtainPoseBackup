#!/usr/bin/env python

import numpy as np
import rospy as ros
from sensor_msgs.msg import Image
from sensor_msgs.msg import CameraInfo
import cv2
import cv2.aruco as aruco
from cv_bridge import CvBridge, CvBridgeError
import roslib
import tf
import yaml

class ArucoDetector(object):

    def __init__(self):
        ''' Initialize the detector '''

        # Initialize ROS node
        ros.init_node("aruco_detector", anonymous=False, log_level=ros.DEBUG)
        self.bridge = CvBridge()
        self.rate = ros.Rate(90) # in hz

        # Initialize ROS Subscriber
        try:
            image_topic = ros.get_param('~image_topic')
        except:
            ros.logerr("Image topic not set in launch file!")
            exit()
        ros.logdebug("Image topic loaded..")
        self.sub = ros.Subscriber(image_topic, Image, self.cbDetect)

        # Initialize tf broadcaster and first tag check
        self.br = tf.TransformBroadcaster()
        self.initial_id = None

        # Grab camera info
        ##TODO: Replace this w/ something that reads from a file if the msg is empty!
        try:
            camera_info_topic = ros.get_param('~camera_info_topic')
        except:
            ros.logerr("Camera_info topic not set in launch file!")
            exit()
        #cam_info_sub = ros.Subscriber(camera_info_topic, CameraInfo, self.cbCamInfo)
        ##DEBUG:
        self.loadCalibration()
        ros.loginfo(self.matrix)

        # Configure detector
        self.aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)
        self.aruco_params = aruco.DetectorParameters_create()

    def loadCalibration(self):
        ''' Load the calibration file and read relevant values'''
        with open('/home/nuc/catkin_ws/src/zayas_test/scripts/ost.yaml','r') as f:
            doc = yaml.load(f)

        self.matrix = np.asarray(doc["camera_matrix"]["data"])
        self.matrix = self.matrix.reshape(3,3)
        self.dist = np.asarray(doc["distortion_coefficients"]["data"])
        ros.loginfo(self.matrix)
        ros.loginfo(self.dist)

    def cbCamInfo(self, msg):
        '''Retrieve cam info data from message'''
        self.matrix = msg.K
        self.dist = msg.D
        ros.loginfo(self.matrix)

    def extractImage(self, msg):
        ''' Extracts the data from the msg and converts to usable numpy array '''
        try:
            image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        except CvBridgeError as e:
            print(e)

        return img

    def detectMarkers(self, frame):
        ''' Detects markers based on default params. '''
        ## TODO: Look into how the parameters are determined
        aruco_params = aruco.DetectorParameters_create()
        corners, ids, rejectedImgPoints = aruco.detectMarkers(frame, self.aruco_dict, parameters = aruco_params)


        ##DEPRECATED:
        #if (len(corners)!=0):
        #    if (self.initLoc != True):
        #        self.br.sendTransform((0,0,0), tf.transformations.quaternion_from_euler(0,0,0),
        #        ros.Time.now(),
        #        "initial_tag",
        #        "map")
        #    self.initLoc = True

        ##DEBUG:
        #ros.logdebug(corners)
        #ros.logdebug(ids)

        return corners, ids

    def obtainPose(self, corners, ids):
        ''' Retrieves pose from given markers '''
        rvecs, tvecs, _objPoints = aruco.estimatePoseSingleMarkers(corners, .185, self.matrix, self.dist)

        ''' If localization hasn't started and a tag is detected, make that
         first tag the 'origin' of our world. When we code for the cornfield
         we can define the exact position of an aruco tag and map estimations
         of the rest and possibly correct for it.'''

        if (self.initial_id == None):
            self.initial_id = ids[0][0]
            self.br.sendTransform((0,0,0), tf.transformations.quaternion_from_euler(0,0,0), ros.Time.now(), "/" + str(ids[0]), "/world")

        #interm = cv2.Rodrigues(rvecs[0][0])
        print("initial id:")
        print(self.initial_id)
        for i in ids:
            if (i!=self.initial_id):
                print(i)
            #self.br.sendTransform(tvecs[0][i],tf.transformations.quaternion_from_euler(rvecs[0][i][0],rvecs[0][i][1],rvecs[0][i][2]), ros.Time.now(), "/" + str(ids[i]), "/camera")
        print("===============")
        #self.br.sendTransform(tvecs[0][0],tf.transformations.quaternion_from_euler(rvecs[0][0][0],rvecs[0][0][1],rvecs[0][0][2]), ros.Time.now(), "/initial_tag", "/camera")

        ##DEBUG:
        #ros.logdebug("=================================================")
        #ros.logdebug("RESULTS: ")
        #ros.logdebug("Rotation Vectors: ")
        #ros.logdebug(rvecs)
        #ros.logdebug("Translation Vectors: ")
        #ros.logdebug(tvecs)

        return rvecs, tvecs

    def drawMarkers(self, corners, frame):
        ''' Draws the detected markers on the frame. '''
        debugFrame = aruco.drawDetectedMarkers(frame, corners)
        #if (rvecs!=None):
        #debugFrame = aruco.drawAxis(debugFrame, self.matrix, self.dist, rvecs, tvecs, 100)
        cv2.imshow('DEBUG', debugFrame)

    def cbDetect(self, msg):
        ''' The main callback loop, run whenever a frame is received. '''
        frame = self.extractImage(msg)

        corners, ids = self.detectMarkers(frame)
        if (len(corners)!=0):
            rvecs, tvecs = self.obtainPose(corners, ids)
            self.drawMarkers(corners,frame)

        ## DEBUG:
        else:
            self.drawMarkers(corners, frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            ros.logfatal("oh no")



if __name__ == '__main__':
    ad = ArucoDetector()
    ros.spin()
